# Sign-Language-Translator ğŸ–ï¸
This project detects and recognizes hand gestures (like alphabets or words such as "HELLO") using hand landmark data and trains a machine learning model with Scikit-learn (RandomForestClassifier) for real-time predictions.

ğŸ“¦ TECH STACK

ğŸ”¹ Python               -     	Main programming language

ğŸ”¹ MediaPipe            -    	Extracts 21 hand landmarks from video frames

ğŸ”¹ OpenCV               -    	Real-time webcam video capture

ğŸ”¹ Scikit-learn	       -      ML model (RandomForestClassifier) for gesture classification

ğŸ”¹ Pandas               -     	Reads and writes dataset to CSV (dataset.csv)

ğŸ”¹ NumPy	               -      Converts landmark data to numeric format for ML processing

ğŸ”¹Pickle               -     	Saves/loads trained ML model

ğŸ”§ FUNCTIONS EXPLAINED
 
 ğŸ”¹collect_data.py â€“ Opens webcam, detects hand, saves landmarks + label to dataset.csv.

 ğŸ”¹train_model.py â€“ Trains a Random Forest model using landmark data, saves it as model.pkl.

 ğŸ”¹app.py â€“ Loads the model, reads webcam feed, predicts the gesture live on screen.

 ğŸ”¹dataset.csv â€“ Stores collected landmark data and labels.

 ğŸ”¹model.pkl â€“ Final trained model used for prediction.

ğŸš€ HOW TO RUN

âœ… Step 1: Install Requirements

pip install opencv-python mediapipe pandas numpy scikit-learn

ğŸ“¸ Step 2: Collect Landmark Data

python collect_data.py

ğŸ”¹Enter a label (e.g., A, HELLO) in the terminal and press Enter

ğŸ”¹The webcam will open

ğŸ”¹Show your gesture to the camera

ğŸ”¹Press s to save a sample

ğŸ”¹Press q or Ctrl+C to exit

ğŸ§  Step 3: Train the Model

python train_model.py

ğŸ”¹Trains using dataset.csv.

ğŸ”¹Shows accuracy score and
Saves the model as model.pkl.

ğŸ‘ï¸ Step 4: Run Real-Time Detection

python app.py

ğŸ”¹Starts webcam.

ğŸ”¹Shows predicted gesture based on current hand position.

ğŸ”¹Press q to quit (or Ctrl+C if it doesnâ€™t respond).

ğŸ“Œ TIPS

âœ”ï¸Supports letters (A, B, etc.) and full words (like HELLO).

âœ”ï¸For best accuracy, collect multiple samples of each gesture.

âœ”ï¸Use consistent hand position and lighting during collection.









